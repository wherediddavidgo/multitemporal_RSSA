{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client as stac_client\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import shapely\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import geometry_mask, rasterize\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio.vrt import WarpedVRT\n",
    "\n",
    "\n",
    "from cv2 import dilate\n",
    "from shapely import bounds\n",
    "from shapely.geometry import box, mapping\n",
    "from shapely.ops import transform as shp_transform\n",
    "from pyproj import Transformer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import datetime\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersects(item_bbox, poly):\n",
    "    return shapely.box(*item_bbox).intersects(poly)\n",
    "\n",
    "\n",
    "def scale_to_reflectance(dn):\n",
    "    return dn.astype('float32') * 1e-4\n",
    "\n",
    "\n",
    "def scale_to_8bit(dn):\n",
    "    return (((dn + 1) / 2) * 255).astype('int8')\n",
    "\n",
    "\n",
    "def normalized_difference(x, y):\n",
    "    denominator = x + y\n",
    "    normalized_diff = (x - y) / np.where(denominator != 0, denominator, np.nan)\n",
    "\n",
    "    return normalized_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14574bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if mode == 'all':\n",
    "    square_path =(r\"C:\\Users\\dego\\Documents\\local_files\\RSSA\\Platte_centerlines_masks\\squares_15x_20251010.shp\")\n",
    "    # pill_path =(r\"C:\\Users\\dego\\Documents\\local_files\\RSSA\\Platte_centerlines_masks\\squares_15x_20251010.shp\")\n",
    "    circle_path =(r\"C:\\Users\\dego\\Documents\\local_files\\RSSA\\Platte_centerlines_masks\\circles_3x_20251010.shp\")\n",
    "    pt_path = (r\"C:\\Users\\dego\\Documents\\local_files\\RSSA\\Platte_centerlines_masks\\points_20251010.shp\")\n",
    "\n",
    "\n",
    "centerline_path = (r\"C:\\Users\\dego\\Documents\\local_files\\RSSA\\Platte_centerlines_masks\\Vector_centerlines\\s2_platte_centerlines.shp\")\n",
    "\n",
    "\n",
    "def _init_worker(square_path, circle_path, centerline_path, href_dict_in):\n",
    "    global squares, circles, vector_centerline, HREFS\n",
    "\n",
    "    \n",
    "    squares = gpd.read_file(square_path).set_crs(4326)\n",
    "    circles = gpd.read_file(circle_path).set_crs(4326)\n",
    "    pts = gpd.read_file(pt_path).set_crs(4326)\n",
    "    vector_centerline = gpd.read_file(centerline_path).set_crs(4326, allow_override=True)\n",
    "\n",
    "    duplicated_iidxes = circles.iindex[circles.iindex.duplicated()]\n",
    "    circles = circles.loc[~circles.iindex.isin(duplicated_iidxes)]\n",
    "\n",
    "    pairs = circles.sjoin(circles, how='inner', predicate='intersects')\n",
    "    pairs = pairs[pairs.iindex_left != pairs.iindex_right].drop_duplicates()\n",
    "\n",
    "    G = nx.from_pandas_edgelist(pairs, source='iindex_left', target='iindex_right')\n",
    "    G.add_nodes_from(circles['iindex'])\n",
    "\n",
    "    comp_map = {n:i for i, comp in enumerate(nx.connected_components(G)) for n in comp}\n",
    "    circles['cluster'] = circles.iindex.map(comp_map)\n",
    "    circles = circles.set_index('iindex')\n",
    "\n",
    "    keep_idx = circles.groupby('cluster').sample(1, random_state=0).index\n",
    "    circles = circles.loc[keep_idx].drop(columns='cluster')\n",
    "\n",
    "    circles = circles.reset_index()\n",
    "    squares = squares.loc[squares.iindex.isin(keep_idx)]\n",
    "    pts = pts.loc[pts.iindex.isin(keep_idx)]\n",
    "\n",
    "    HREFS = href_dict_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57631445",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac = stac_client.open('https://earth-search.aws.element84.com/v1')\n",
    "\n",
    "gage_search = stac.search(\n",
    "    collections=['sentinel-2-l2a'],\n",
    "    bbox=circles.total_bounds.tolist(),\n",
    "    datetime='2018-01-01/2024-12-31',\n",
    "    query={'eo:cloud_cover': {'lt': 20}},\n",
    "    fields={'include': ['id', 'assets.B03', 'assets.B08', 'assets.SCL', 'bbox', 'properties.datetime']}\n",
    ")\n",
    "items = list(gage_search.items())\n",
    "\n",
    "work = []\n",
    "for item in tqdm(items):\n",
    "    ibox = item.bbox\n",
    "    b3_href = item.assets['green'].href\n",
    "    b8_href = item.assets['nir'].href\n",
    "    scl_href = item.assets['scl'].href\n",
    "\n",
    "    for idx, row in circles.iterrows():\n",
    "        if intersects(ibox, row[2]):\n",
    "            work.append((item, row[0], b3_href, b8_href, scl_href))\n",
    "\n",
    "id_hrefs = pd.DataFrame(work, columns=['img', 'iindex', 'b3_href', 'b8_href', 'scl_href'])\n",
    "\n",
    "id_hrefs['img_id'] = id_hrefs.apply(lambda x: str(x['img']).split('=')[1][0:24], axis=1)\n",
    "id_hrefs['mgrs'] = id_hrefs.apply(lambda x: x['img_id'].split('_')[1], axis=1)\n",
    "id_hrefs['date'] = id_hrefs.apply(lambda x: datetime.date(int(x['img_id'][10:14]), int(x['img_id'][14:16]), int(x['img_id'][16:18])), axis=1)\n",
    "id_hrefs['version'] = id_hrefs.apply(lambda x: x['img_id'].split('_')[3], axis=1)\n",
    "\n",
    "# find duplicate images with different processing levels\n",
    "\n",
    "tile_dts = []\n",
    "tile_dt_versions = []\n",
    "for row in tqdm(id_hrefs.iterrows()):\n",
    "    tile = row[1]['mgrs']\n",
    "    dt = row[1]['date']\n",
    "    version = row[1]['version']\n",
    "    tile_dts.append((tile, dt))\n",
    "    tile_dt_versions.append((tile, dt, version))\n",
    "\n",
    "\n",
    "tile_dt_version_df = pd.DataFrame(set(tile_dt_versions), columns=['mgrs', 'date', 'version'])\\\n",
    "    .sort_values('date')\n",
    "nonduplicates = []\n",
    "\n",
    "for combo in tqdm(set(tile_dts)):\n",
    "    temp_mgrs = combo[0]\n",
    "    temp_dt = combo[1]\n",
    "    temp_df = tile_dt_version_df.loc[(tile_dt_version_df.mgrs == temp_mgrs) & (tile_dt_version_df.date == temp_dt)]\\\n",
    "        .sort_values('version', ascending=False)\\\n",
    "        .reset_index()\n",
    "\n",
    "    df_out = temp_df.head(1)\n",
    "    nonduplicates.append(df_out)\n",
    "\n",
    "nonduplicates = pd.concat(nonduplicates)\n",
    "\n",
    "\n",
    "\n",
    "nonduplicate_id_hrefs = pd.merge(id_hrefs, nonduplicates[['mgrs', 'date', 'version']], how='right', on=['mgrs', 'date', 'version'])\n",
    "nonduplicate_id_hrefs['year'] = nonduplicate_id_hrefs.apply(lambda x: x['date'].year, axis=1)\n",
    "nonduplicate_id_hrefs['month'] = nonduplicate_id_hrefs.apply(lambda x: x['date'].month, axis=1)\n",
    "\n",
    "nonduplicate_id_hrefs = nonduplicate_id_hrefs.set_index(['img_id', 'iindex'])\n",
    "\n",
    "# # if mode == 'all':\n",
    "# #     nonduplicate_id_hrefs.to_csv('/content/drive/MyDrive/all_sites/nonduplicate_stac_ids_hrefs_20250928.csv')\n",
    "# # elif mode == 'extra_gages':\n",
    "# #     nonduplicate_id_hrefs.to_csv('/content/drive/MyDrive/river_tinder_assets/gage_sites/nonduplicate_gage_stac_ids_extra.csv')\n",
    "# # elif mode == 'gage':\n",
    "# #     nonduplicate_id_hrefs.to_csv('/content/drive/MyDrive/river_tinder_assets/gage_sites/nonduplicate_gage_stac_ids_20250921.csv')\n",
    "nonduplicate_id_hrefs.to_csv(r\"C:\\Users\\dego\\Documents\\local_files\\RSSA\\stac_img_ids_20251012.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonduplicate_id_hrefs = pd.read_csv(r\"C:\\Users\\dego\\Documents\\local_files\\RSSA\\stac_img_ids_20251012.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53517905",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in [2018, 2019, 2020, 2021, 2022, 2023, 2024]:\n",
    "    tdf = nonduplicate_id_hrefs.loc[nonduplicate_id_hrefs.year == year]\n",
    "    tdf.to_csv(f\"C:/Users/dego/Documents/local_files/RSSA/stac_img_ids_{year}_20251012.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def ref_geoms_from_b3href(b3_href, poly_idx, view_geoms, effwidth_geoms, centerline_geoms):\n",
    "    with rasterio.open(b3_href) as src:\n",
    "        img_crs = src.crs\n",
    "    # print(poly_idx)\n",
    "    view_geom = view_geoms.set_index('iindex').loc[poly_idx].geometry\n",
    "    eff_geom = effwidth_geoms.set_index('iindex').loc[poly_idx].geometry\n",
    "\n",
    "    t_view = Transformer.from_crs(view_geoms.crs, img_crs,  always_xy=True).transform\n",
    "    t_eff = Transformer.from_crs(effwidth_geoms.crs, img_crs, always_xy=True).transform\n",
    "\n",
    "    view_src = shp_transform(t_view, view_geom)\n",
    "    eff_src  = shp_transform(t_eff,  eff_geom)\n",
    "\n",
    "    # Filter lines by intersection in image CRS, then reproject only those (cheap)\n",
    "    if centerline_geoms.crs != img_crs:\n",
    "        cl_img = centerline_geoms.to_crs(img_crs)\n",
    "    else:\n",
    "        cl_img = centerline_geoms\n",
    "    hits = list(cl_img.sindex.query(eff_src, predicate=\"intersects\"))\n",
    "    lines_in_bound = cl_img.iloc[hits].copy()\n",
    "\n",
    "    return view_src, eff_src, lines_in_bound\n",
    "\n",
    "\n",
    "def dn_to_reflectance(band):\n",
    "    return np.float32(band) * 1e-4\n",
    "\n",
    "\n",
    "def normalized_difference(b1, b2):\n",
    "    denominator = b1 + b2\n",
    "    numerator = b1 - b2\n",
    "    return numerator / np.where(denominator != 0, denominator, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_image_from_hrefs(b3_href, b8_href, scl_href, view_geom, otsu_geom):\n",
    "    l, b, r, t = map(float, view_geom.bounds)\n",
    "\n",
    "    with rasterio.open(b3_href) as b3_src:\n",
    "        window = rasterio.windows.from_bounds(l, b, r, t, b3_src.transform).round_offsets().round_lengths()\n",
    "        transform = b3_src.window_transform(window)\n",
    "\n",
    "        h, w = window.height, window.width\n",
    "\n",
    "        if h == 0 or w == 0:\n",
    "            return np.array([1]), None, None, None, None, None\n",
    "\n",
    "        b3v = b3_src.read(1, window=window, masked=True)\n",
    "        b3_crs = b3_src.crs\n",
    "\n",
    "    with rasterio.open(b8_href) as b8_src:\n",
    "        b8v = b8_src.read(1, window=window, masked=True)\n",
    "\n",
    "    with rasterio.open(scl_href) as scl_src, WarpedVRT(\n",
    "        scl_src, crs=b3_crs, transform=transform, width=w, height=h, resampling=Resampling.nearest\n",
    "    ) as vrt:\n",
    "        sclv = vrt.read(1)\n",
    "\n",
    "    b3v = dn_to_reflectance(b3v)\n",
    "    b8v = dn_to_reflectance(b8v)\n",
    "    ndwi_v = normalized_difference(b3v, b8v)\n",
    "    otsu_geom_mask = geometry_mask([otsu_geom], out_shape=(h, w), transform=transform, invert=True)\n",
    "    # return otsu_geom_mask, ndwi_v\n",
    "    if otsu_geom_mask.size <= ndwi_v.size:\n",
    "        ndwi_o = np.ma.array(ndwi_v, mask=~otsu_geom_mask).compressed()\n",
    "        b8o = np.ma.array(b8v, mask=~otsu_geom_mask).compressed()\n",
    "\n",
    "        if ndwi_o.size >= 10:\n",
    "            ndwi_threshold = threshold_otsu(ndwi_o)\n",
    "            nir_threshold = threshold_otsu(b8o)\n",
    "        else:\n",
    "            ndwi_threshold = 1\n",
    "            nir_threshold = 1\n",
    "\n",
    "        wmask = (ndwi_v >= ndwi_threshold) & (b8v <= nir_threshold)\n",
    "        cloudmask = np.isin(sclv, [7, 8, 9]).astype('uint8')\n",
    "        snowmask = (sclv == 11).astype('uint8')\n",
    "        ndmask = (sclv != 0).astype('uint8')\n",
    "\n",
    "        return ndwi_v, wmask, cloudmask, snowmask, ndmask, transform, ndwi_threshold, nir_threshold\n",
    "    else:\n",
    "        return np.array([1]), None, None, None, None, None, None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def identify_river(wmask, lines, window_trans):\n",
    "    h, w = wmask.shape\n",
    "    wbool = wmask.filled(0) > 0\n",
    "    # rbuffs = lines.copy().buffer(5)\n",
    "    shapes = ((geom, 1) for geom in lines.geometry)\n",
    "    river_seed = rasterize(\n",
    "        shapes=shapes,\n",
    "        out_shape= (h, w),\n",
    "        transform=window_trans,\n",
    "        fill=0,\n",
    "        dtype='uint8',\n",
    "        all_touched=True\n",
    "    )\n",
    "    structure = np.ones((3, 3), dtype=bool)\n",
    "    river_mask = ndi.binary_propagation(input=river_seed * wbool, mask=wbool, structure=structure)\n",
    "    return river_mask\n",
    "\n",
    "\n",
    "def GENERATE_MASKS(img_id, poly_idx, squares, circles, vector_centerlines, HREFS):\n",
    "    b3_href, b8_href, scl_href = HREFS[(img_id, poly_idx)]\n",
    "\n",
    "    circle_geom, lines = ref_geoms_from_b3href(b3_href, poly_idx, circles, vector_centerlines)\n",
    "\n",
    "    ndwi_v, wmask, cloudmask, snowmask, ndmask, wwindow_transform = process_image_from_hrefs(b3_href, b8_href, scl_href, circle_geom)\n",
    "\n",
    "    if ndwi_v.size > 1:\n",
    "\n",
    "        rmask = identify_river(wmask, lines, wwindow_transform)\n",
    "\n",
    "        return ndwi_v, rmask, cloudmask, snowmask, ndmask, wwindow_transform, circle_geom\n",
    "    else:\n",
    "        return np.array([1]), None, None, None, None, None, None\n",
    "\n",
    "\n",
    "def count_pixels(rmask, cloudmask, snowmask, ndmask, transform, circle, ndwi_v):\n",
    "    if rmask is not None:\n",
    "        circle_mask = rasterize([circle], out_shape = rmask.shape, transform=transform, dtype='uint8', all_touched=True) == 1\n",
    "\n",
    "        kernel = np.array([[0, 1, 0],\n",
    "                        [1, 1, 1],\n",
    "                        [0, 1, 0]]).astype('uint8')\n",
    "\n",
    "        ring_mask = dilate(circle_mask.astype('uint8'), kernel, iterations=1) & ~circle_mask\n",
    "\n",
    "        r = rmask.astype(bool)\n",
    "        c = cloudmask.astype(bool)\n",
    "        s = snowmask.astype(bool)\n",
    "        v = ndmask.astype(bool)\n",
    "\n",
    "        n_pixels = np.count_nonzero(circle_mask)\n",
    "        n_valid = np.count_nonzero(circle_mask & v)\n",
    "        n_river = np.count_nonzero(circle_mask & r)\n",
    "        n_cloud = np.count_nonzero(circle_mask & c)\n",
    "        n_snow = np.count_nonzero(circle_mask & s)\n",
    "        n_cloudriver = np.count_nonzero(circle_mask & r & c)\n",
    "\n",
    "        n_edge = np.count_nonzero(ring_mask)\n",
    "        n_edgeriver = np.count_nonzero(ring_mask & r)\n",
    "\n",
    "        return n_pixels, n_valid, n_river, n_cloud, n_snow, n_cloudriver, n_edge, n_edgeriver, np.nanmean(np.where(circle_mask, ndwi_v, np.nan))\n",
    "\n",
    "    else:\n",
    "        return -999, -999, -999, -999, -999, -999, -999, -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a285cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(img_id, poly_idx, squares, circles, vector_centerlines):\n",
    "\n",
    "    b3 = nonduplicate_id_hrefs.loc[(nonduplicate_id_hrefs.img_id == img_id) & (nonduplicate_id_hrefs.iindex == poly_idx)].reset_index()['b3_href'][0]\n",
    "    b8 = nonduplicate_id_hrefs.loc[(nonduplicate_id_hrefs.img_id == img_id) & (nonduplicate_id_hrefs.iindex == poly_idx)].reset_index()['b8_href'][0]\n",
    "    scl = nonduplicate_id_hrefs.loc[(nonduplicate_id_hrefs.img_id == img_id) & (nonduplicate_id_hrefs.iindex == poly_idx)].reset_index()['scl_href'][0]\n",
    "\n",
    "    square, circle, lines = ref_geoms_from_b3href(b3, poly_idx, squares, circles, vector_centerlines)\n",
    "    ndwi, wmask, cloud, snow, valid, transform, ndwi_threshold, nir_threshold = process_image_from_hrefs(b3, b8, scl, square, circle)\n",
    "\n",
    "\n",
    "    rmask = identify_river(wmask, lines, transform)\n",
    "    rm_cdict = {\n",
    "            'red':   [[0.0, 0.0, 0.0],\n",
    "                      [1.0, 1.0, 1.0]],\n",
    "            'green': [[0.0, 0.0, 0.0],\n",
    "                      [1.0, 0.0, 0.0]],\n",
    "            'blue':  [[0.0, 0.0, 0.0],\n",
    "                      [1.0, 0.0, 0.0]],\n",
    "            'alpha': [[0.0, 0.0, 0.0],\n",
    "                      [1.0, 0.35, 1.0]]\n",
    "        }\n",
    "    rm_cmap = LinearSegmentedColormap('custom_cmap', segmentdata=rm_cdict)\n",
    "\n",
    "    cm_cdict = {\n",
    "        'red':      [[0.0, 0.0, 0.0],\n",
    "                     [1.0, 0.0, 0.0]],\n",
    "        'green':    [[0.0, 0.0, 0.0],\n",
    "                     [1.0, 0.0, 0.0]],\n",
    "        'blue':     [[0.0, 0.0, 0.0],\n",
    "                     [1.0, 1.0, 0.0]],\n",
    "        'alpha':    [[0.0, 0.0, 0.0],\n",
    "                     [1.0, 0.35, 1.0]]\n",
    "    }\n",
    "    cm_cmap = LinearSegmentedColormap('custom_cmap', segmentdata=cm_cdict)\n",
    "\n",
    "    sm_cdict = {\n",
    "        'red':      [[0.0, 0.0, 0.0],\n",
    "                     [1.0, 0.0, 0.0]],\n",
    "        'green':    [[0.0, 0.0, 0.0],\n",
    "                     [1.0, 1.0, 0.0]],\n",
    "        'blue':     [[0.0, 0.0, 0.0],\n",
    "                     [1.0, 0.0, 0.0]],\n",
    "        'alpha':    [[0.0, 0.0, 0.0],\n",
    "                     [1.0, 0.2, 1.0]]\n",
    "    }\n",
    "    sm_cmap = LinearSegmentedColormap('custom_cmap', segmentdata=sm_cdict)\n",
    "\n",
    "    if ndwi.size > 1:\n",
    "        fig, (ax1) = plt.subplots(ncols=1, nrows=1)\n",
    "        show(ndwi, cmap='Greys_r', ax=ax1, transform=transform)\n",
    "        show(rmask, cmap=rm_cmap, ax=ax1, transform=transform)\n",
    "        show(cloud, cmap=cm_cmap, ax=ax1, transform=transform)\n",
    "        show(snow, cmap=sm_cmap, ax=ax1, transform=transform)\n",
    "        show(valid, cmap=sm_cmap, ax=ax1, transform=transform)\n",
    "        gpd.GeoSeries([circle]).plot(ax=ax1, facecolor='none', edgecolor='tab:blue')\n",
    "        (lines).plot(ax=ax1)\n",
    "        ax1.set_title(f'{img_id}_{poly_idx}')\n",
    "        # n_pixels, n_valid, n_river, n_cloud, n_snow, n_cloudriver, n_edge, n_edgeriver, meanndwi = count_pixels(rmask, cloud, snow, valid, transform, circle, ndwi)\n",
    "        # print(f'{img_id}, {ndwi_threshold}, {meanndwi}, {n_river}')\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    else:\n",
    "        print('not enough in window')\n",
    "\n",
    "        return -999\n",
    "    # tfig = plt.Figure()\n",
    "    # ax_ndwi = tfig.add_subplot(1, 2, 1)\n",
    "    # show(ndwi, cmap='Greys_r', ax=ax_ndwi)\n",
    "    # ax_scl = tfig.add_subplot(1, 2, 2)\n",
    "    # show(ndmask, cmap='Paired', ax=ax_scl)\n",
    "    # tfig.suptitle(f'{img_id}_{poly_idx}')\n",
    "    # tfig.tight_layout()\n",
    "\n",
    "    # return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb85d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_plot(img_id, poly_idx, squares, circles, vector_centerlines):\n",
    "    p = show_plot(img_id, poly_idx, squares, circles, vector_centerlines)\n",
    "    if type(p) != int:\n",
    "        p.savefig(f'C:/Users/dego/Documents/local_files/RSSA/RT_exports/{img_id}_{poly_idx}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ccb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "year_imgs = {}\n",
    "month_imgs = {}\n",
    "\n",
    "\n",
    "\n",
    "href_dict = {(row.img_id, int(row.iindex)): (row.b3_href, row.b8_href, row.scl_href)\n",
    "    for _, row in nonduplicate_id_hrefs.reset_index().iterrows()}\n",
    "\n",
    "_init_worker(square_path, circle_path, centerline_path, href_dict)\n",
    "\n",
    "\n",
    "def _worker(args):\n",
    "    img_id, idx = args\n",
    "    # return idx\n",
    "    try:\n",
    "        ndwi, rmask, cloudmask, snowmask, ndmask, trans, circle_poly = GENERATE_MASKS(\n",
    "            img_id, idx, squares, circles, vector_centerline\n",
    "        )\n",
    "        if ndwi.size < 1:\n",
    "            return(img_id, idx, -999, -999, -999, -999, -999, -999, -999, -999)\n",
    "\n",
    "        return(img_id, idx, *count_pixels(rmask, cloudmask, snowmask, ndmask, trans, circle_poly))\n",
    "\n",
    "    except Exception:\n",
    "        return(img_id, idx, -999, -999, -999, -999, -999, -999, -999, -999)\n",
    "\n",
    "\n",
    "paths = (square_path, circle_path, centerline_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94827f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bcdb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in years:\n",
    "    month_imgs = {}\n",
    "    for m in months:\n",
    "        month_imgs[m] = nonduplicate_id_hrefs.loc[(nonduplicate_id_hrefs.month == m) & (nonduplicate_id_hrefs.year == y)]\n",
    "            # .set_index(['img_id', 'iindex'])\n",
    "        # print(month_imgs[m].head())\n",
    "    year_imgs[y] = month_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50485abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_imgs[2024][12].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8562926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=min(4, mp.cpu_count()), initializer=_init_worker, initargs=(paths[0], paths[1], paths[2], href_dict)) as ex:\n",
    "    # for y in years:\n",
    "    #     for m in months:\n",
    "            # path_out = (f'/content/drive/MyDrive/effwidth_results/all_sites/effwidths_{m}_{y}_20250928.csv')\n",
    "            # if path_out not in glob.glob(os.path.join('/content/drive/MyDrive/effwidth_results/all_sites/effwidths_*.csv')):\n",
    "\n",
    "    tempdf = year_imgs[y][m]\n",
    "    recs = tempdf.index.tolist()\n",
    "\n",
    "    rows = list(tqdm(ex.map(_worker, recs, chunksize=8), total=len(recs), desc=f'{y}_{m}'))\n",
    "    output = pd.DataFrame(rows, columns=['img_id', 'iindex', 'n_pixels', 'n_valid', 'n_river', 'n_cloud', 'n_snow', 'n_cloudriver', 'n_edge', 'n_edgeriver'])\n",
    "    # output.to_csv(path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "_init_worker(square_path, circle_path, centerline_path, href_dict, circles.iindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7ef738",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 35\n",
    "tindx = 82571\n",
    "\n",
    "tnih = nonduplicate_id_hrefs.loc[nonduplicate_id_hrefs.iindex == tindx]\n",
    "tnih['date'] = pd.to_datetime(tnih.date).dt.date\n",
    "tnih = tnih.sort_values('date')\n",
    "tnih = tnih.reset_index()\n",
    "\n",
    "for n in range(0, 100):\n",
    "    tid = tnih.loc[n, 'img_id']\n",
    "    # tindx = tnih.loc[n, 'iindex']\n",
    "\n",
    "    f = show_plot(tid, tindx, squares, circles, vector_centerline)\n",
    "# circles.loc[circles.iindex == tindx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abaf193",
   "metadata": {},
   "outputs": [],
   "source": [
    "tindx = 82571\n",
    "\n",
    "tnih = nonduplicate_id_hrefs.loc[nonduplicate_id_hrefs.iindex == tindx]\n",
    "tnih['date'] = pd.to_datetime(tnih.date).dt.date\n",
    "tnih = tnih.sort_values('date')\n",
    "tnih\n",
    "# tid = 'S2A_14TPM_20180627_1_L2A'\n",
    "# # tid = 'S2A_14TMM_20241222_0_L2A'\n",
    "for tid in tqdm(tnih.img_id):\n",
    "    print('poop')\n",
    "    # export_plot(tid, tindx, squares, circles, vector_centerline)\n",
    "    print('cant actually export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b5e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonduplicate_id_hrefs.loc[(nonduplicate_id_hrefs.img_id == tid) & (nonduplicate_id_hrefs.iindex == tindx)].reset_index()['b3_href'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi_v, rmask, cloudmask, snowmask, ndmask, wwindow_transform, circle_geom = GENERATE_MASKS(tid, tindx, circles, vector_centerline)\n",
    "count_pixels(rmask, cloudmask, snowmask, ndmask, wwindow_transform, circle_geom)\n",
    "# n_pixels, n_valid, n_river, n_cloud, n_snow, n_cloudriver, n_edge, n_edgeriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "squares.set_index('iindex').loc[256673]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c138ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HREFS[(tid, tindx)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rssa_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
